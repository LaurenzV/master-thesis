= Conclusion & Future Work <conclusion>

The main goal of this thesis was to determine whether sparse strips are a suitable approach for implementing a state-of-the-art 2D renderer. To this end, we built a CPU-based 2D renderer with the given paradigm at its core to validate that all of the features expected of a 2D renderer are compatible with the approach#footnote[Other commonly-expected features of a 2D renderer include masks, clip paths and layer isolation, which _are_ supported by Vello CPU, but have not been treated in this work due to space reasons.]. Our experiments demonstrate that Vello CPU exhibits competitive performance in most cases for small-sized shapes and outperforms nearly all other renderers, including Skia or Cairo, as the shape size increases. An exception is Blend2D, which our renderer cannot beat in the vast majority of cases in terms of raw performance output, which we largely attribute to the efforts that have been put into optimizing the library. We also show that Vello CPU can achieve even higher speedups by making use of multi-threading, something that many other mainstream renderer cannot make use of due to architectural reasons. It is therefore valid to draw the conclusion that the sparse strips paradigm is very effective and forms a suitable and promising basis for a performant renderer.

Four avenues for future work that could be explored are now presented.

First, it would be interesting to look into how this approach could be adapted for GPU-based rendering. While CPU-based rendering has its use cases, for most interactive rendering workloads it is usually preferable to make use of hardware-acceleration for better throughput. In fact, at the time of writing, there is already an ongoing parallel attempt to create a CPU/GPU-hybrid renderer #footnote[https://github.com/linebender/vello/tree/main/sparse_strips/vello_hybrid (accessed on 11.09.2025)] where the CPU is responsible for all stages up to coarse rasterization and the final fine rasterization happens on the GPU. This current approach already works and highlights the usefulness of having a pipeline consisting of separated stages with well-defined inputs and outputs, but there is a lot more exploration work to be done. A further interesting question would be to determine whether the strip generation stage (in particular, the part of strip generation that is responsible for calculating anti-aliasing) can be moved to the GPU as well, so that all the heavy pixel-level calculations are completely performed on the GPU, while only the more sequential parts of the pipeline (flattening, tile generation and coarse rasterization) are done by the CPU. As part of this, it might also be worthwhile to explore whether a different tile size (for example 8x8) is more suitable for GPU-based rendering compared to the currently-used 4x4 tile size on CPU. While doing so would mean that we need to perform more superfluous anti-aliasing calculations, this is not as much of a problem since the GPU can do those much faster than the CPU. The advantage is that it will reduce the time needed for tile generation and sorting on the CPU, which is likely to form a bottleneck in this GPU-first approach.

Next, the evaluation has shown that Vello CPU has a certain weakness when handling small geometries. It was also asserted that the most-likely culprit for this behavior is, apart from some algorithmic inefficiencies that should also be addressed, the fixed 4x4 size of tiles, resulting in unnecessary computational work during strip generation. While it is not possible to introduce variable-height strips, it _is_ possible to introduce variable-width strips. The way this could be achieved is by letting each tile store the horizontal extents of the containing line and then only computing winding numbers for pixel-columns that are actually covered by a line. A possible downside would be that future steps in the pipeline can no longer assume that the width of a strip is a multiple of four, an assumption that is at the moment baked into most of the SIMD code.

Third, as was briefly touched upon in @pixel-level-winding, a considerable advantage of adopting the sparse strips approach is that it allows for efficient path caching, which is especially relevant when rendering scenes with lots of text. Unlike traditional approaches where caching usually requires rendering the path to an intermediate bitmap image, in our case it is possible to only cache the sparse strips representation of the path, leading to lighter storage requirements, especially as the size of the path increases. With that said, there are is a challenge that needs to be addressed for the technique to be fully viable. When caching a glyph#footnote[In very simplifying terms, a glyph _roughly_ corresponds to a letter in the alphabet. Therefore, when talking about glyph caching, it refers to the ability to cache the rendered outline of a letter so that it can be reused in different locations on the screen.], the usual expectation is that it can be reused multiple times in different locations, so that we can for example first render the letter "t" at the location (120, 135) and then a second time at the location (133, 160). Applying an x-shift to the sparse strips representation of a path is not too challenging as it simply involves updating the x coordinate of each strip. However, a considerable difficulty are shifts in the y direction. The problem is that strips have a fixed height of four, and it is therefore not easily possible to apply arbitrary y shifts to it, unless the shift happens to be a multiple of four. An interesting research direction would therefore be figuring out whether it is possible to efficiently update the sparse strips representation of a path to make translations in the vertical direction possible.

Finally, the fourth major point that could benefit from more dedicated attention is multi-threading. On the one hand, this includes investigating more closely why the speedup for parallel fine rasterization is not as high as expected. On the other hand, this requires more fundamentally exploring how coarse rasterization, which currently forms the only serial bottleneck in the pipeline, can be made more parallel. As was previously mentioned, there are different approaches that could be explored, like attempting to perform parts of coarse rasterization _within_ the worker, but it remains to be determined whether it can be fully parallelized in a performant way. 
