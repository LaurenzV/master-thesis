= Introduction

2D rendering lies at the heart of virtually all our interactions with digital devices. Whether it be web browsers on our computers, news apps on our phones or ticket machines at the nearest train station: They all rely on 2D rendering to present a user interface that we can interact with.

In most cases, it is preferable to make use of GPUs during the rendering process. GPUs excel at performing hundreds of thousands of computations at the same time, which fits nicely into the 2D rendering paradigm where the colors for millions of pixels need to be computed as quickly as possible. The importance of GPUs in this area is reflected by the fact that the vast majority of research in this direction makes use of them @gpu_accelerated_path_rendering @efficient_gpu_path_rendering_scanline @massively_parallel_vector_graphics.

With that said, utilizing the GPU does come at a cost, and there are situations where it makes more sense to accept the trade-off of (often) slower rendering times by running the rendering pipeline on the CPU instead. To name three concrete advantages of doing so:

- *Portability*: By relying on the GPU, it is implicitly assumed that the host system actually has a GPU available. While this might be the case for most modern consumer-grade devices, it might not be the case for embedded devices or server appliances. In addition to that, when utilizing the GPU, there are many different competing graphic APIs to choose from, such as Vulkan #footnote[https://www.vulkan.org (accessed on 15.09.2025)] or OpenGL #footnote[https://www.opengl.org (accessed on 15.09.2025)], which come with their own set of trade-offs with regard to platform compatibility. In contrast, by removing any dependency on external GPUs and solely relying on the CPU, it is guaranteed that the program will run on any kind of device as long as a supported target architecture is used.
- *Complexity*: Interfacing into the GPU usually entails a whole lot of additional complexity that is necessary to properly manage the resources and pass data between the GPU and the host system. For applications with high levels of interactivity, like graphical user interfaces, where having the best performance is absolutely critical, this is often a trade-off worth taking. Still, there are many other situations where maintaining low code complexity and small binary sizes has higher priority, making the simplicity of CPUs more attractive. 
- *Performance*: In comparison to CPUs, GPUs undoubtedly have the upper hand when it comes to processing millions of pixels at the same time. Yet, GPUs do also have performance cliffs. For example, there can be a significant latency during the first startup as the GPU context needs to be initialized and set up. This latency might not be a problem for GUI applications where a one-time startup latency is barely noticeable, but it could become cumbersome in situations where we only want to run a one-time rendering operation, for example when rendering a single image.

Doing 2D rendering on the CPU is in some sense an already solved problem, as there already exists a plethora of libraries that can do the job, including for example Skia #footnote[https://skia.org (accessed on 15.09.2025)] or Cairo #footnote[https://www.cairographics.org (accessed on 15.09.2025)], which have both been existing for more than a decade. However, the question of which _fundamental_ approach to rendering is the best from the standpoint of performance and efficiency is an open research question. This is especially true as the capabilities of our CPUs have been constantly evolving, with the addition of features like SIMD and multi-threading offering new opportunities for exploring and researching different rendering paradigms. This is evidenced by the recent emergence of Blend2D #footnote[https://blend2d.com (accessed on 15.09.2025)], a CPU-renderer that for the first time offers multi-threading capabilities and beats all existing renderers by a wide margin in many benchmarks according to @blend2d_perf, in part thanks to a novel rendering architecture based on just-in-time compilation.

The main motivation for this thesis is two-fold. On the one hand, I wish to fill an important gap in literature, as 2D rendering is a subfield of computer graphics that has generally received little academic interest in recent years. My hope is that this work can serve as an introduction into this field by explaining relevant foundational knowledge in an approachable way based on the inner workings of a feature-complete and performant CPU-based 2D renderer in an approachable manner.

On the other hand, I want to make a contribution to the research question of finding the "best" rendering technique by exploring a novel rendering paradigm that is based on so-called _sparse strips_, a new sparsely encoded representation of rendered vector paths. This paradigm borrows some key ideas from the concept of so-called _merged boundary fragments_ as they are presented by #cite(<efficient_gpu_path_rendering_scanline>, form: "prose") (although originally intended for GPU-based rendering), but provides better compatibility with CPUs by extending the idea in a number of ways to make it more amenable to SIMD optimizations and multi-threading. In order to validate the idea, I spearhead the development of a new CPU-based renderer called _Vello CPU_ #footnote[https://github.com/linebender/vello/tree/main/sparse_strips/vello_cpu (accessed on 15.09.2025)] as part of this master's thesis. It is fully based on the sparse strips idea and supports most features that are usually expected from a 2D renderer. The implementation is done using the Rust programming language.

The remainder of this thesis is structured as follows: In @background, some of the basic concepts of 2D rendering will be explained, as they are prerequisites for the following chapters. In @implementation, a holistic overview of the whole architecture of Vello CPU and its implementation be given by providing detailed explanations of the functionality of each part of the rendering pipeline. Two additional subsections will be dedicated to describing how the pipeline is SIMD-optimized and made compatible with multi-threading. In @comparison, we will contrast the design of Vello CPU against two other renderers to highlight similarities but also emphasize the novelties of our architecture.  In @evaluation, the performance of Vello CPU will be comprehensively evaluated by running it against the Blend2D benchmark suite @blend2d_perf and comparing the performance against many other available CPU-based 2D renderers. Finally, in @conclusion, the main findings will be summarized and suggestions for potential future work will be given.

== Contribution notice <contrib-notice>
It needs to be noted that the project of building Vello CPU is part of a bigger collaboration involving external contributors, where another goal is to build another 2D renderer based on the sparse strips paradigm that also utilizes the GPU to achieve even better performance. Additionally, Vello CPU was not created completely from scratch during this thesis, but borrows some code from an earlier prototype. Therefore, the description of some parts of the pipeline in @implementation are included as they are indispensable to gain a full understanding of how the renderer works, but were at least partly co-implemented by other parties. For full transparency, a description of the timeline leading up to the start of the thesis as well as the contributions that have been specifically made as part of the thesis is provided below.

The sparse strips approach was first sketched out by Raph Levien in January 2024 in the form of an informal document#footnote[https://docs.google.com/document/d/16dlcHvvLMumRa5MAyk2Du_MsjF32w0G-n7L9NOJUbRI/edit?tab=t.0#heading=h.9lokdzrz8r5x (accessed on 05.10.2025)] that summarizes the main idea. After a few months of experimentation with a focus on integrating the idea into a GPU renderer, Raph developed a CPU-only prototype#footnote[https://github.com/linebender/piet/pull/589 (accessed on 03.10.2025)] as part of a week-long research retreat in late 2024, demonstrating that the idea can in principle be implemented on the CPU. Nevertheless, the prototype still left many pressing questions unanswered. On the one hand, it was unclear whether approach could be extended to support commonly-expected features like rendering gradients and images as well as doing blending and compositing. On the other hand, it had not been fully determined yet in which ways SIMD could be integrated in the pipeline and whether a performant multi-threaded rendering approach was possible. Resolving these open research question to arrive at a clear conclusion on whether a renderer based on sparse strips can outperform or at least compete with existing renderers formed the main motivation of this thesis.

To this purpose, I made the following contributions: First, I rewrote the existing version of the fine rasterization and packing stages (see @fine_rasterization and @packing) completely from scratch to add support for a `f32`-based (32-bit floating point numbers) as well as `u8`-based (8-bit unsigned integers) rendering mode. I also extended the fine rasterization stage to support rendering gradients and images and performing blending and compositing. 

Next, I did an in-depth analysis of the performance profile using Apple Instruments to identify bottlenecks and discover optimization opportunities in all parts of the pipeline. As part of this, I have for example come up with two crucial optimizations for curve flattening (as explained in @flatten_opt) that lead to drastic speedups.

In order to support SIMD, I made major contributions to the fearless_simd#footnote[https://github.com/linebender/fearless_simd (accessed on 03.10.2025)] library to support the necessary arithmetic operations for NEON and SSE4.2. Using that, I rewrote the flattening, strips generation, fine rasterization and packing stages (see @overview_pipeline) to actually make use of SIMD.

The last major contribution implementation-wise was the multi-threaded rendering mode. This included coming up with the right architecture as well as experimenting with different approaches and synchronization primitives to support the design.

Finally, as described in @evaluation, I created C bindings to integrate three different Rust-based renderers, including Vello CPU, into the Blend2D benchmark harness and did the analysis and interpretation of the results.