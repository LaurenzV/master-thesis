= Introduction

In many cases, especially for interactive, real-time rendering where achieving a high number of frames per second is important, the rendering process it at least to some degree accelerated by using the GPU: GPUs excel at performing thousands of computations at the same, which fits nicely into the 2D rendering paradigm, where the color for millions of pixels should be calculated as quickly as possible. With that said, utilizing the GPU does come at a cost, and there are situations where it makes more sense to accept the trade-off of slower rendering times by running the rendering pipeline on the CPU instead. Some of the advantages of doing so include:

- *Portability*: By relying on the GPU, you are implicitly assuming that the host system actually has a GPU available, which might be the case for most modern consumer-grade devices, but for example might not be the case for embedded devices or server appliances. In addition to that, there are many different competing graphic APIs available such as Vulkan @vulkan_homepage or OpenGL @opengl_homepage, which come with their own set of trade-offs with regards to platform compatibility. On the other hand, by solely making use of the CPU, you can be sure that your program will run on any device as long as it uses a target architecture supported by the compiler.
- *Complexity*: Interfacing into the GPU usually entails a whole lot of additional complexity that is necessary to properly manage the resources and pass data between the GPU and CPU. In situations with high levels of interactivity (e.g. GUI applications) where having the best performance is absolutely critical, this is usually a trade-off worth taking. But there are many other situations where it is much more desirable to keep code complexity and binary sizes low, and good performance is only a secondary goal. Being able to use a renderer _without_ all of this additional complexity can be very useful in this case.

